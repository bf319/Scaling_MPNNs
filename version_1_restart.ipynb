{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "version-1-restart.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZQi9X7wjG0aFD/Vp919gK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bf319/Scaling_MPNNs/blob/main/version_1_restart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Uuxp631d21",
        "outputId": "103753cb-404d-47c8-f1fa-bfad90d8cf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 75 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 70 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.3 MB/s \n",
            "\u001b[?25h  Building wheel for jaxline (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.2 MB/s \n",
            "\u001b[?25h  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 5.4 MB/s \n",
            "\u001b[?25h  Building wheel for metis (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q git+https://github.com/deepmind/dm-haiku\n",
        "%pip install -q jraph\n",
        "%pip install -q git+https://github.com/deepmind/jaxline\n",
        "%pip install -q ogb\n",
        "%pip install -q dgl\n",
        "%pip install -q optax\n",
        "%pip install -q metis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## I think this is not necessary for doing the partition\n",
        "\n",
        "# ## Install METIS\n",
        "# %rm metis-*\n",
        "# !wget http://glaros.dtc.umn.edu/gkhome/fetch/sw/metis/metis-5.1.0.tar.gz\n",
        "# !gunzip metis-5.1.0.tar.gz\n",
        "# !tar -xvf metis-5.1.0.tar\n",
        "\n",
        "# %cd metis-5.1.0/\n",
        "# !make config shared=1\n",
        "# !make install\n",
        "\n",
        "# %env METIS_DLL=/usr/local/lib/libmetis.so"
      ],
      "metadata": {
        "id": "POz3sIZ2bqnE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TPU\n",
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()"
      ],
      "metadata": {
        "id": "LKDGqcZC1xKh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.nodeproppred import Evaluator\n",
        "from ogb.nodeproppred import DglNodePropPredDataset\n",
        "\n",
        "dataset = DglNodePropPredDataset(name = \"ogbn-proteins\")\n",
        "split_idx = dataset.get_idx_split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYocthafCOE7",
        "outputId": "a1168424-57a2-4ed8-e009-ab6b29ab7fce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/proteins.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.21 GB: 100%|██████████| 216/216 [00:06<00:00, 33.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/proteins.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into DGL objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There is only one graph in Node Property Prediction datasets\n",
        "ogbn_proteins_main_graph, ogbn_proteins_main_labels = dataset[0]\n",
        "\n",
        "'''\n",
        "  OGBN-Proteins\n",
        "    #Nodes = 132,534\n",
        "    #Edges = 39,561,252\n",
        "    #Tasks = 112\n",
        "    #Split Type = Species\n",
        "    #Task Type = Binary classification\n",
        "    #Metric = ROC-AUC\n",
        "\n",
        "    Task:\n",
        "      The task is to predict the presence of protein functions in a multi-label binary classification setup,\n",
        "      where there are 112 kinds of labels to predict in total. \n",
        "      The performance is measured by the average of ROC-AUC scores across the 112 tasks.\n",
        "\n",
        "    #Others:\n",
        "      **undirected**\n",
        "      **weighted**\n",
        "      **typed (according to species)**\n",
        "\n",
        "  (1) Nodes represent proteins\n",
        "    (1.1) The proteins come from 8 species\n",
        "      len(set(graph.ndata['species'].reshape(-1).tolist())) == 8\n",
        "    (1.2) Each node has one feature associated with it (its species)\n",
        "      graph.ndata['species'].shape == (#nodes, 1)\n",
        "  \n",
        "  (2) Edges indicate different types of biologically meaningful associations between proteins\n",
        "    (2.1) All edges come with 8-dimensional features\n",
        "      graph.edata['feat'].shape == (2 * #edges, 8)\n",
        "\n",
        "'''\n",
        "# Get split labels\n",
        "train_label = dataset.labels[split_idx['train']]  # (86619, 112)\n",
        "valid_label = dataset.labels[split_idx['valid']]  # (21236, 112)\n",
        "test_label = dataset.labels[split_idx['test']]    # (24679, 112)"
      ],
      "metadata": {
        "id": "uoD9dO9ECiCd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "\n",
        "'''\n",
        "  Generate graph partition using metis, with balanced number of edges in each partition.\n",
        "  Note: \n",
        "    The subgraphs do not contain the node/edge data in the input graph (https://docs.dgl.ai/generated/dgl.metis_partition.html)\n",
        "'''\n",
        "num_partitions = 10\n",
        "dgl_graph_metis_partition = dgl.metis_partition(ogbn_proteins_main_graph, num_partitions, balance_edges = True)"
      ],
      "metadata": {
        "id": "vNNZP95xvy-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import jraph\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def dgl_graph_to_jraph(node_ids):\n",
        "  # First add back the node and edge features\n",
        "  dgl_graph_with_features = dgl.node_subgraph(ogbn_proteins_main_graph, node_ids)\n",
        "\n",
        "  node_features = jnp.array(dgl_graph_with_features.ndata['species'])\n",
        "  \n",
        "  # TODO: Check if order is correct\n",
        "  # I think it should be -- DGLGraph.edges uses the default (uv) format for edges\n",
        "  # with u == source and v == destination\n",
        "  # From https://docs.dgl.ai/generated/dgl.DGLGraph.edges.html#dgl.DGLGraph.edges\n",
        "  senders = jnp.array(dgl_graph_with_features.edges()[0])\n",
        "  receivers = jnp.array(dgl_graph_with_features.edges()[1])\n",
        "\n",
        "  # Edges -- here we should include the 8-dimensional edge features\n",
        "  edges = jnp.array(dgl_graph_with_features.edata['feat'])\n",
        "\n",
        "  n_node = jnp.array([dgl_graph_with_features.num_nodes()])\n",
        "  n_edge = jnp.array([dgl_graph_with_features.num_edges()])\n",
        "\n",
        "  return jraph.GraphsTuple(\n",
        "            nodes = node_features, \n",
        "            senders = senders, \n",
        "            receivers = receivers,\n",
        "            edges = edges,   \n",
        "            n_node = n_node, \n",
        "            n_edge = n_edge,\n",
        "            globals = None  # No global features\n",
        "          )\n",
        "  \n",
        "def get_labels_for_subgraph(node_ids):\n",
        "  return ogbn_proteins_main_labels.index_select(0, node_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NIrv0oSO2El",
        "outputId": "fdb5d6f6-431f-4d58-941d-05948688afbc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 10.151 seconds\n",
            "Construct multi-constraint weights: 0.124 seconds\n",
            "Metis partitioning: 50.304 seconds\n",
            "Split the graph: 11.026 seconds\n",
            "Construct subgraphs: 0.130 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_partitions):\n",
        "  node_ids = dgl_graph_metis_partition[i].ndata['_ID']\n",
        "\n",
        "  jraph_graph = dgl_graph_to_jraph(node_ids)\n",
        "  labels = get_labels_for_subgraph(node_ids)"
      ],
      "metadata": {
        "id": "TijuLfigrPKx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jraph\n",
        "\n",
        "def network_definition(graph: jraph.GraphsTuple):\n",
        "  \"\"\"Defines a graph neural network.\n",
        "  Args:\n",
        "    graph: GraphsTuple the network processes.\n",
        "  Returns:\n",
        "  \"\"\"\n",
        "  update_node_fn = hk.Sequential(\n",
        "      hk.nets.MLP([128]),\n",
        "      hk.LayerNorm(axis = -1, create_scale = True, create_offset = True)\n",
        "      )\n",
        "  \n",
        "  update_edge_fn = hk.Sequential(\n",
        "      hk.nets.MLP([128]),\n",
        "      hk.LayerNorm(axis = -1, create_scale = True, create_offset = True)\n",
        "      )\n",
        "\n",
        "  gn = jraph.InteractionNetwork(\n",
        "      update_edge_fn=update_edge_fn,\n",
        "      update_node_fn=update_node_fn\n",
        "      )"
      ],
      "metadata": {
        "id": "dT-ybNnT2E_x"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}