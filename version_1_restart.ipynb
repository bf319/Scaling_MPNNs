{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "version-1-restart.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtRYIKDHbWQasi4huzNGez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bf319/Scaling_MPNNs/blob/main/version_1_restart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Uuxp631d21",
        "outputId": "2fac73c7-c663-407a-db8f-881af5f310ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 75 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 70 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.2 MB/s \n",
            "\u001b[?25h  Building wheel for jaxline (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 78 kB 2.9 MB/s \n",
            "\u001b[?25h  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 5.2 MB/s \n",
            "\u001b[?25h  Building wheel for metis (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q git+https://github.com/deepmind/dm-haiku\n",
        "%pip install -q jraph\n",
        "%pip install -q git+https://github.com/deepmind/jaxline\n",
        "%pip install -q ogb\n",
        "%pip install -q dgl\n",
        "%pip install -q optax\n",
        "%pip install -q metis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## I think this is not necessary for doing the partition\n",
        "\n",
        "# ## Install METIS\n",
        "# %rm metis-*\n",
        "# !wget http://glaros.dtc.umn.edu/gkhome/fetch/sw/metis/metis-5.1.0.tar.gz\n",
        "# !gunzip metis-5.1.0.tar.gz\n",
        "# !tar -xvf metis-5.1.0.tar\n",
        "\n",
        "# %cd metis-5.1.0/\n",
        "# !make config shared=1\n",
        "# !make install\n",
        "\n",
        "# %env METIS_DLL=/usr/local/lib/libmetis.so"
      ],
      "metadata": {
        "id": "POz3sIZ2bqnE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TPU\n",
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()"
      ],
      "metadata": {
        "id": "LKDGqcZC1xKh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.nodeproppred import Evaluator\n",
        "from ogb.nodeproppred import DglNodePropPredDataset\n",
        "\n",
        "dataset = DglNodePropPredDataset(name = \"ogbn-proteins\")\n",
        "split_idx = dataset.get_idx_split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYocthafCOE7",
        "outputId": "198c4e00-6a48-4f66-d3af-3e2581f233c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/proteins.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.21 GB: 100%|██████████| 216/216 [00:16<00:00, 12.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/proteins.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:05<00:00,  5.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into DGL objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There is only one graph in Node Property Prediction datasets\n",
        "ogbn_proteins_main_graph, ogbn_proteins_main_labels = dataset[0]\n",
        "\n",
        "'''\n",
        "  OGBN-Proteins\n",
        "    #Nodes = 132,534\n",
        "    #Edges = 39,561,252\n",
        "    #Tasks = 112\n",
        "    #Split Type = Species\n",
        "    #Task Type = Binary classification\n",
        "    #Metric = ROC-AUC\n",
        "\n",
        "    Task:\n",
        "      The task is to predict the presence of protein functions in a multi-label binary classification setup,\n",
        "      where there are 112 kinds of labels to predict in total. \n",
        "      The performance is measured by the average of ROC-AUC scores across the 112 tasks.\n",
        "\n",
        "    #Others:\n",
        "      **undirected**\n",
        "      **weighted**\n",
        "      **typed (according to species)**\n",
        "\n",
        "  (1) Nodes represent proteins\n",
        "    (1.1) The proteins come from 8 species\n",
        "      len(set(graph.ndata['species'].reshape(-1).tolist())) == 8\n",
        "    (1.2) Each node has one feature associated with it (its species)\n",
        "      graph.ndata['species'].shape == (#nodes, 1)\n",
        "  \n",
        "  (2) Edges indicate different types of biologically meaningful associations between proteins\n",
        "    (2.1) All edges come with 8-dimensional features\n",
        "      graph.edata['feat'].shape == (2 * #edges, 8)\n",
        "\n",
        "'''\n",
        "# Get split labels\n",
        "train_label = dataset.labels[split_idx['train']]  # (86619, 112)\n",
        "valid_label = dataset.labels[split_idx['valid']]  # (21236, 112)\n",
        "test_label = dataset.labels[split_idx['test']]    # (24679, 112)"
      ],
      "metadata": {
        "id": "uoD9dO9ECiCd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "\n",
        "'''\n",
        "  Generate graph partition using metis, with balanced number of edges in each partition.\n",
        "  Note: \n",
        "    The subgraphs do not contain the node/edge data in the input graph (https://docs.dgl.ai/generated/dgl.metis_partition.html)\n",
        "'''\n",
        "num_partitions = 10\n",
        "dgl_graph_metis_partition = dgl.metis_partition(ogbn_proteins_main_graph, num_partitions, balance_edges = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNNZP95xvy-v",
        "outputId": "1db6c6c5-d5f9-4f77-a139-9ef30fd55290"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 8.475 seconds\n",
            "Construct multi-constraint weights: 0.073 seconds\n",
            "Metis partitioning: 42.739 seconds\n",
            "Split the graph: 11.870 seconds\n",
            "Construct subgraphs: 0.198 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import jraph\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def dgl_graph_to_jraph(node_ids):\n",
        "  # First add back the node and edge features\n",
        "  dgl_graph_with_features = dgl.node_subgraph(ogbn_proteins_main_graph, node_ids)\n",
        "\n",
        "  node_features = jnp.array(dgl_graph_with_features.ndata['species'])\n",
        "  \n",
        "  # TODO: Check if order is correct\n",
        "  # I think it should be -- DGLGraph.edges uses the default (uv) format for edges\n",
        "  # with u == source and v == destination\n",
        "  # From https://docs.dgl.ai/generated/dgl.DGLGraph.edges.html#dgl.DGLGraph.edges\n",
        "  senders = jnp.array(dgl_graph_with_features.edges()[0])\n",
        "  receivers = jnp.array(dgl_graph_with_features.edges()[1])\n",
        "\n",
        "  # Edges -- here we should include the 8-dimensional edge features\n",
        "  edges = jnp.array(dgl_graph_with_features.edata['feat'])\n",
        "\n",
        "  n_node = jnp.array([dgl_graph_with_features.num_nodes()])\n",
        "  n_edge = jnp.array([dgl_graph_with_features.num_edges()])\n",
        "\n",
        "  return jraph.GraphsTuple(\n",
        "            nodes = node_features, \n",
        "            senders = senders, \n",
        "            receivers = receivers,\n",
        "            edges = edges,   \n",
        "            n_node = n_node, \n",
        "            n_edge = n_edge,\n",
        "            globals = None  # No global features\n",
        "          )\n",
        "  \n",
        "def get_labels_for_subgraph(node_ids):\n",
        "  return ogbn_proteins_main_labels.index_select(0, node_ids)"
      ],
      "metadata": {
        "id": "6NIrv0oSO2El"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_partitions):\n",
        "  node_ids = dgl_graph_metis_partition[i].ndata['_ID']\n",
        "\n",
        "  jraph_graph = dgl_graph_to_jraph(node_ids)\n",
        "  labels = get_labels_for_subgraph(node_ids)"
      ],
      "metadata": {
        "id": "TijuLfigrPKx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jraph"
      ],
      "metadata": {
        "id": "fZpbzvwpa1Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def network_definition(graph: jraph.GraphsTuple):\n",
        "#   \"\"\"Defines a graph neural network.\n",
        "#   Args:\n",
        "#     graph: GraphsTuple the network processes.\n",
        "#   Returns:\n",
        "#   \"\"\"\n",
        "#   update_node_fn = hk.Sequential(\n",
        "#       hk.nets.MLP([128]),\n",
        "#       hk.LayerNorm(axis = -1, create_scale = True, create_offset = True)\n",
        "#       )\n",
        "  \n",
        "#   update_edge_fn = hk.Sequential(\n",
        "#       hk.nets.MLP([128]),\n",
        "#       hk.LayerNorm(axis = -1, create_scale = True, create_offset = True)\n",
        "#       )\n",
        "\n",
        "#   gn = jraph.InteractionNetwork(\n",
        "#       update_edge_fn=update_edge_fn,\n",
        "#       update_node_fn=update_node_fn\n",
        "#       )\n",
        "  \n",
        "# # From https://github.com/deepmind/deepmind-research/blob/master/ogb_lsc/pcq/model.py\n",
        "# def _softmax_cross_entropy(\n",
        "#     logits: jnp.DeviceArray,\n",
        "#     targets: jnp.DeviceArray,\n",
        "# ) -> jnp.DeviceArray:\n",
        "#   logits = jax.nn.log_softmax(logits)\n",
        "#   return -jnp.sum(targets * logits, axis=-1)\n",
        "\n",
        "# def get_loss(pred, targets):\n",
        "#   targets /= jnp.maximum(1., jnp.sum(targets, axis=-1, keepdims=True))\n",
        "#   loss = _softmax_cross_entropy(pred, targets)\n",
        "\n",
        "#   return loss\n"
      ],
      "metadata": {
        "id": "dT-ybNnT2E_x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from typing import Callable, NamedTuple, Sequence\n",
        "\n",
        "# def _get_activation_fn(name: str) -> Callable[[jnp.ndarray], jnp.ndarray]:\n",
        "#   if name == 'identity':\n",
        "#     return lambda x: x\n",
        "#   if hasattr(jax.nn, name):\n",
        "#     return getattr(jax.nn, name)\n",
        "#   raise ValueError('Unknown activation function %s specified. '\n",
        "#                    'See https://jax.readthedocs.io/en/latest/jax.nn.html'\n",
        "#                    'for the list of supported function names.')\n",
        "  \n",
        "# class ModelOutput(NamedTuple):\n",
        "#   node_embeddings: jnp.ndarray\n",
        "#   node_embedding_projections: jnp.ndarray\n",
        "#   node_projection_predictions: jnp.ndarray\n",
        "#   node_logits: jnp.ndarray\n",
        "\n",
        "# class MyModuleVersion1(hk.Module):\n",
        "#   def __init__(\n",
        "#       self,\n",
        "#       mlp_hidden_sizes: Sequence[int],\n",
        "#       latent_size: int,\n",
        "#       num_classes: int,\n",
        "#       num_message_passing_steps: int = 2,\n",
        "#       activation: str = 'relu',\n",
        "#       dropout_rate: float = 0.0,\n",
        "#       dropedge_rate: float = 0.0,\n",
        "#       use_sent_edges: bool = False,\n",
        "#       disable_edge_updates: bool = False,\n",
        "#       normalization_type: str = 'layer_norm',\n",
        "#       aggregation_function: str = 'sum',\n",
        "#       name='MyModuleVersion1',\n",
        "#   ):\n",
        "#     super().__init__(name=name)\n",
        "#     self._num_classes = num_classes\n",
        "#     self._latent_size = latent_size\n",
        "#     self._output_sizes = list(mlp_hidden_sizes) + [latent_size]\n",
        "#     self._num_message_passing_steps = num_message_passing_steps\n",
        "#     self._activation = _get_activation_fn(activation)\n",
        "#     self._dropout_rate = dropout_rate\n",
        "#     self._dropedge_rate = dropedge_rate\n",
        "#     self._use_sent_edges = use_sent_edges\n",
        "#     self._disable_edge_updates = disable_edge_updates\n",
        "#     self._normalization_type = normalization_type\n",
        "#     self._aggregation_function = aggregation_function\n",
        "\n",
        "#     def _dropout_graph(self, graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "#       node_key, edge_key = hk.next_rng_keys(2)\n",
        "#       nodes = hk.dropout(node_key, self._dropout_rate, graph.nodes)\n",
        "#       edges = graph.edges\n",
        "#       if not self._disable_edge_updates:\n",
        "#         edges = hk.dropout(edge_key, self._dropout_rate, edges)\n",
        "#       return graph._replace(nodes=nodes, edges=edges)\n",
        "\n",
        "#     def build_gn(\n",
        "#         output_sizes: Sequence[int],\n",
        "#         activation: Callable[[jnp.ndarray], jnp.ndarray],\n",
        "#         suffix: str,\n",
        "#         use_sent_edges: bool,\n",
        "#         is_training: bool,\n",
        "#         dropedge_rate: float,\n",
        "#         normalization_type: str,\n",
        "#         aggregation_function: str,\n",
        "#     ):\n",
        "#       \"\"\"Builds an InteractionNetwork with MLP update functions.\"\"\"\n",
        "#       node_update_fn = build_update_fn(\n",
        "#           f'node_processor_{suffix}',\n",
        "#           output_sizes,\n",
        "#           activation=activation,\n",
        "#           normalization_type=normalization_type,\n",
        "#           is_training=is_training,\n",
        "#       )\n",
        "#       edge_update_fn = build_update_fn(\n",
        "#           f'edge_processor_{suffix}',\n",
        "#           output_sizes,\n",
        "#           activation=activation,\n",
        "#           normalization_type=normalization_type,\n",
        "#           is_training=is_training,\n",
        "#       )\n",
        "\n",
        "#     def build_update_fn(\n",
        "#         name: str,\n",
        "#         output_sizes: Sequence[int],\n",
        "#         activation: Callable[[jnp.ndarray], jnp.ndarray],\n",
        "#         normalization_type: str,\n",
        "#         is_training: bool,\n",
        "#     ):\n",
        "#       \"\"\"Builds update function.\"\"\"\n",
        "\n",
        "#       def single_mlp(inner_name: str):\n",
        "#         \"\"\"Creates a single MLP performing the update.\"\"\"\n",
        "#         mlp = hk.nets.MLP(\n",
        "#             output_sizes=output_sizes,\n",
        "#             name=inner_name,\n",
        "#             activation=activation)\n",
        "#         mlp = jraph.concatenated_args(mlp)\n",
        "#         if normalization_type == 'layer_norm':\n",
        "#           norm = hk.LayerNorm(\n",
        "#               axis=-1,\n",
        "#               create_scale=True,\n",
        "#               create_offset=True,\n",
        "#               name=name + '_layer_norm')\n",
        "#         elif normalization_type == 'batch_norm':\n",
        "#           batch_norm = hk.BatchNorm(\n",
        "#               create_scale=True,\n",
        "#               create_offset=True,\n",
        "#               decay_rate=0.9,\n",
        "#               name=f'{inner_name}_batch_norm',\n",
        "#               cross_replica_axis=None if hk.running_init() else 'i',\n",
        "#           )\n",
        "#           norm = lambda x: batch_norm(x, is_training)\n",
        "#         elif normalization_type == 'none':\n",
        "#           return mlp\n",
        "#         else:\n",
        "#           raise ValueError(f'Unknown normalization type {normalization_type}')\n",
        "#         return jraph.concatenated_args(hk.Sequential([mlp, norm]))\n",
        "\n",
        "#       return single_mlp(f'{name}_homogeneous')\n",
        "\n",
        "#     def _encode(\n",
        "#         self,\n",
        "#         graph: jraph.GraphsTuple,\n",
        "#         is_training: bool,\n",
        "#     ) -> jraph.GraphsTuple:\n",
        "#       node_embed_fn = build_update_fn(\n",
        "#           'node_encoder',\n",
        "#           self._output_sizes,\n",
        "#           activation=self._activation,\n",
        "#           normalization_type=self._normalization_type,\n",
        "#           is_training=is_training,\n",
        "#       )\n",
        "#       edge_embed_fn = build_update_fn(\n",
        "#           'edge_encoder',\n",
        "#           self._output_sizes,\n",
        "#           activation=self._activation,\n",
        "#           normalization_type=self._normalization_type,\n",
        "#           is_training=is_training,\n",
        "#       )\n",
        "#       gn = jraph.GraphMapFeatures(edge_embed_fn, node_embed_fn)\n",
        "#       graph = gn(graph)\n",
        "#       if is_training:\n",
        "#         graph = self._dropout_graph(graph)\n",
        "#       return graph\n",
        "\n",
        "#     def _process(\n",
        "#         self,\n",
        "#         graph: jraph.GraphsTuple,\n",
        "#         is_training: bool,\n",
        "#     ) -> jraph.GraphsTuple:\n",
        "#       for idx in range(self._num_message_passing_steps):\n",
        "#         net = build_gn(\n",
        "#             output_sizes=self._output_sizes,\n",
        "#             activation=self._activation,\n",
        "#             suffix=str(idx),\n",
        "#             use_sent_edges=self._use_sent_edges,\n",
        "#             is_training=is_training,\n",
        "#             dropedge_rate=self._dropedge_rate,\n",
        "#             normalization_type=self._normalization_type,\n",
        "#             aggregation_function=self._aggregation_function)\n",
        "#         residual_graph = net(graph)\n",
        "#         graph = graph._replace(nodes=graph.nodes + residual_graph.nodes)\n",
        "#         if not self._disable_edge_updates:\n",
        "#           graph = graph._replace(edges=graph.edges + residual_graph.edges)\n",
        "#         if is_training:\n",
        "#           graph = self._dropout_graph(graph)\n",
        "#       return graph\n",
        "\n",
        "#     def _node_mlp(\n",
        "#         self,\n",
        "#         graph: jraph.GraphsTuple,\n",
        "#         is_training: bool,\n",
        "#         output_size: int,\n",
        "#         name: str,\n",
        "#     ) -> jnp.ndarray:\n",
        "#       decoder_sizes = list(self._output_sizes[:-1]) + [output_size]\n",
        "#       net = build_update_fn(\n",
        "#           name,\n",
        "#           decoder_sizes,\n",
        "#           self._activation,\n",
        "#           normalization_type=self._normalization_type,\n",
        "#           is_training=is_training,\n",
        "#       )\n",
        "#       return net(graph.nodes)\n",
        "\n",
        "#     def __call__(\n",
        "#         self,\n",
        "#         graph: jraph.GraphsTuple,\n",
        "#         is_training: bool,\n",
        "#         stop_gradient_embedding_to_logits: bool = False,\n",
        "#     ) -> ModelOutput:\n",
        "#       # Note that these update configs may need to change if\n",
        "#       # we switch back to GraphNetwork rather than InteractionNetwork.\n",
        "\n",
        "#       graph = self._encode(graph, is_training)\n",
        "#       graph = self._process(graph, is_training)\n",
        "#       node_embeddings = graph.nodes\n",
        "#       node_projections = self._node_mlp(graph, is_training, self._latent_size,\n",
        "#                                         'projector')\n",
        "#       node_predictions = self._node_mlp(\n",
        "#           graph._replace(nodes=node_projections),\n",
        "#           is_training,\n",
        "#           self._latent_size,\n",
        "#           'predictor',\n",
        "#       )\n",
        "#       if stop_gradient_embedding_to_logits:\n",
        "#         graph = jax.tree_map(jax.lax.stop_gradient, graph)\n",
        "#       node_logits = self._node_mlp(graph, is_training, self._num_classes,\n",
        "#                                   'logits_decoder')\n",
        "#       return ModelOutput(\n",
        "#           node_embeddings=node_embeddings,\n",
        "#           node_logits=node_logits,\n",
        "#           node_embedding_projections=node_projections,\n",
        "#           node_projection_predictions=node_predictions,\n",
        "#       )"
      ],
      "metadata": {
        "id": "LAtsd4s3X_95"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def try_to_apply_interaction_network():\n",
        "  def network_definition(\n",
        "      graph: jraph.GraphsTuple,\n",
        "      num_message_passing_steps: int = 1) -> jraph.ArrayTree:\n",
        "    \"\"\"Defines a graph neural network.\n",
        "    Args:\n",
        "      graph: Graphstuple the network processes.\n",
        "      num_message_passing_steps: number of message passing steps.\n",
        "    Returns:\n",
        "      Decoded nodes.\n",
        "    \"\"\"\n",
        "    # Functions from https://github.com/deepmind/jraph/blob/38817e3a75b8a70e87abdc2c8ed00c40822f10b4/jraph/examples/lstm.py#L112\n",
        "    def update_edge_fn(edges, sender_nodes, receiver_nodes):\n",
        "      # We will run an LSTM memory on the inputs first, and then\n",
        "      # process the output of the LSTM with an MLP.\n",
        "      return hk.Sequential([hk.Linear(64), jax.nn.relu])(edges)\n",
        "\n",
        "    def update_node_fn(nodes, received_edges):\n",
        "      # Note `received_edges.state` will also contain the aggregated state for\n",
        "      # all received edges, which we may choose to use in the node update.\n",
        "      node_inputs = jnp.concatenate([nodes, received_edges], axis=-1)\n",
        "      \n",
        "      return hk.Sequential([hk.Linear(64), jax.nn.relu])(node_inputs)\n",
        "\n",
        "    gn = jraph.InteractionNetwork(\n",
        "          update_edge_fn=update_edge_fn,\n",
        "          update_node_fn=update_node_fn)\n",
        "\n",
        "    for _ in range(num_message_passing_steps):\n",
        "      graph = gn(graph)\n",
        "\n",
        "    return graph\n",
        "\n",
        "  network = hk.without_apply_rng(hk.transform(network_definition))\n",
        "\n",
        "  jraph_graph = dgl_graph_to_jraph(dgl_graph_metis_partition[0].ndata['_ID'])\n",
        "  labels = get_labels_for_subgraph(dgl_graph_metis_partition[0].ndata['_ID'])\n",
        "\n",
        "  params = network.init(jax.random.PRNGKey(42), jraph_graph)\n",
        "\n",
        "  print(network.apply(params, jraph_graph).nodes.shape)\n",
        "  print(jraph_graph.nodes.shape)\n",
        "\n",
        "try_to_apply_interaction_network()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCcfHPSAhCnX",
        "outputId": "bc8c0e56-c1c8-4aec-ce71-e25e8e568c9c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14984, 64)\n",
            "(14984, 1)\n"
          ]
        }
      ]
    }
  ]
}