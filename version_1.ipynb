{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "version-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNShtYmeZB/qHVGBnNchnCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bf319/L45/blob/main/version_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q git+https://github.com/deepmind/dm-haiku\n",
        "%pip install -q jraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4rKEoR7AfGU",
        "outputId": "b6e3a70c-71ac-4ac6-c09e-39225882f18d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 75 kB 2.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TPU\n",
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()"
      ],
      "metadata": {
        "id": "mjOleIc9A5h6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bTz8o3Mx__Zx"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, NamedTuple, Sequence\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_REDUCER_NAMES = {\n",
        "    'sum':\n",
        "        jax.ops.segment_sum,\n",
        "    'mean':\n",
        "        jraph.segment_mean,\n",
        "    'softmax':\n",
        "        jraph.segment_softmax,\n",
        "}"
      ],
      "metadata": {
        "id": "xSor9J9XCSfA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://github.com/deepmind/deepmind-research/blob/master/ogb_lsc/mag/models.py#L42\n",
        "def build_update_fn(\n",
        "    name: str,\n",
        "    output_sizes: Sequence[int],\n",
        "    activation: Callable[[jnp.ndarray], jnp.ndarray],\n",
        "    normalization_type: str,\n",
        "    is_training: bool,\n",
        "):\n",
        "  \"\"\"Builds update function.\"\"\"\n",
        "\n",
        "  def single_mlp(inner_name: str):\n",
        "    \"\"\"Creates a single MLP performing the update.\"\"\"\n",
        "    mlp = hk.nets.MLP(\n",
        "        output_sizes=output_sizes,\n",
        "        name=inner_name,\n",
        "        activation=activation)\n",
        "    mlp = jraph.concatenated_args(mlp)\n",
        "    if normalization_type == 'layer_norm':\n",
        "      norm = hk.LayerNorm(\n",
        "          axis=-1,\n",
        "          create_scale=True,\n",
        "          create_offset=True,\n",
        "          name=name + '_layer_norm')\n",
        "    elif normalization_type == 'batch_norm':\n",
        "      batch_norm = hk.BatchNorm(\n",
        "          create_scale=True,\n",
        "          create_offset=True,\n",
        "          decay_rate=0.9,\n",
        "          name=f'{inner_name}_batch_norm',\n",
        "          cross_replica_axis=None if hk.running_init() else 'i',\n",
        "      )\n",
        "      norm = lambda x: batch_norm(x, is_training)\n",
        "    elif normalization_type == 'none':\n",
        "      return mlp\n",
        "    else:\n",
        "      raise ValueError(f'Unknown normalization type {normalization_type}')\n",
        "    return jraph.concatenated_args(hk.Sequential([mlp, norm]))\n",
        "\n",
        "  return single_mlp(f'{name}_homogeneous')"
      ],
      "metadata": {
        "id": "f8elus6QCB9g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://github.com/deepmind/deepmind-research/blob/master/ogb_lsc/mag/models.py#L82\n",
        "def build_gn(\n",
        "    output_sizes: Sequence[int],\n",
        "    activation: Callable[[jnp.ndarray], jnp.ndarray],\n",
        "    suffix: str,\n",
        "    use_sent_edges: bool,\n",
        "    is_training: bool,\n",
        "    dropedge_rate: float,\n",
        "    normalization_type: str,\n",
        "    aggregation_function: str,\n",
        "):\n",
        "  \"\"\"Builds an InteractionNetwork with MLP update functions.\"\"\"\n",
        "  node_update_fn = build_update_fn(\n",
        "      f'node_processor_{suffix}',\n",
        "      output_sizes,\n",
        "      activation=activation,\n",
        "      normalization_type=normalization_type,\n",
        "      is_training=is_training,\n",
        "  )\n",
        "  edge_update_fn = build_update_fn(\n",
        "      f'edge_processor_{suffix}',\n",
        "      output_sizes,\n",
        "      activation=activation,\n",
        "      normalization_type=normalization_type,\n",
        "      is_training=is_training,\n",
        "  )\n",
        "\n",
        "  def maybe_dropedge(x):\n",
        "    \"\"\"Dropout on edge messages.\"\"\"\n",
        "    if not is_training:\n",
        "      return x\n",
        "    return x * hk.dropout(\n",
        "        hk.next_rng_key(),\n",
        "        dropedge_rate,\n",
        "        jnp.ones([x.shape[0], 1]),\n",
        "    )\n",
        "\n",
        "  dropped_edge_update_fn = lambda *args: maybe_dropedge(edge_update_fn(*args))\n",
        "  return jraph.InteractionNetwork(\n",
        "      update_edge_fn=dropped_edge_update_fn,\n",
        "      update_node_fn=node_update_fn,\n",
        "      aggregate_edges_for_nodes_fn=_REDUCER_NAMES[aggregation_function],\n",
        "      include_sent_messages_in_node_update=use_sent_edges,\n",
        "  )\n",
        "\n",
        "def _get_activation_fn(name: str) -> Callable[[jnp.ndarray], jnp.ndarray]:\n",
        "  if name == 'identity':\n",
        "    return lambda x: x\n",
        "  if hasattr(jax.nn, name):\n",
        "    return getattr(jax.nn, name)\n",
        "  raise ValueError('Unknown activation function %s specified. '\n",
        "                   'See https://jax.readthedocs.io/en/latest/jax.nn.html'\n",
        "                   'for the list of supported function names.')\n",
        "\n",
        "class ModelOutput(NamedTuple):\n",
        "  node_embeddings: jnp.ndarray\n",
        "  node_embedding_projections: jnp.ndarray\n",
        "  node_projection_predictions: jnp.ndarray\n",
        "  node_logits: jnp.ndarray\n",
        "\n",
        "class NodePropertyEncodeProcessDecode(hk.Module):\n",
        "  \"\"\"Node Property Prediction Encode Process Decode Model.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      mlp_hidden_sizes: Sequence[int],\n",
        "      latent_size: int,\n",
        "      num_classes: int,\n",
        "      num_message_passing_steps: int = 2,\n",
        "      activation: str = 'relu',\n",
        "      dropout_rate: float = 0.0,\n",
        "      dropedge_rate: float = 0.0,\n",
        "      use_sent_edges: bool = False,\n",
        "      disable_edge_updates: bool = False,\n",
        "      normalization_type: str = 'layer_norm',\n",
        "      aggregation_function: str = 'sum',\n",
        "      name='NodePropertyEncodeProcessDecode',\n",
        "  ):\n",
        "    super().__init__(name=name)\n",
        "    self._num_classes = num_classes\n",
        "    self._latent_size = latent_size\n",
        "    self._output_sizes = list(mlp_hidden_sizes) + [latent_size]\n",
        "    self._num_message_passing_steps = num_message_passing_steps\n",
        "    self._activation = _get_activation_fn(activation)\n",
        "    self._dropout_rate = dropout_rate\n",
        "    self._dropedge_rate = dropedge_rate\n",
        "    self._use_sent_edges = use_sent_edges\n",
        "    self._disable_edge_updates = disable_edge_updates\n",
        "    self._normalization_type = normalization_type\n",
        "    self._aggregation_function = aggregation_function\n",
        "\n",
        "  def _dropout_graph(self, graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "    node_key, edge_key = hk.next_rng_keys(2)\n",
        "    nodes = hk.dropout(node_key, self._dropout_rate, graph.nodes)\n",
        "    edges = graph.edges\n",
        "    if not self._disable_edge_updates:\n",
        "      edges = hk.dropout(edge_key, self._dropout_rate, edges)\n",
        "    return graph._replace(nodes=nodes, edges=edges)\n",
        "\n",
        "  def _encode(\n",
        "      self,\n",
        "      graph: jraph.GraphsTuple,\n",
        "      is_training: bool,\n",
        "  ) -> jraph.GraphsTuple:\n",
        "    node_embed_fn = build_update_fn(\n",
        "        'node_encoder',\n",
        "        self._output_sizes,\n",
        "        activation=self._activation,\n",
        "        normalization_type=self._normalization_type,\n",
        "        is_training=is_training,\n",
        "    )\n",
        "    edge_embed_fn = build_update_fn(\n",
        "        'edge_encoder',\n",
        "        self._output_sizes,\n",
        "        activation=self._activation,\n",
        "        normalization_type=self._normalization_type,\n",
        "        is_training=is_training,\n",
        "    )\n",
        "    gn = jraph.GraphMapFeatures(edge_embed_fn, node_embed_fn)\n",
        "    graph = gn(graph)\n",
        "    if is_training:\n",
        "      graph = self._dropout_graph(graph)\n",
        "    return graph\n",
        "\n",
        "  def _process(\n",
        "      self,\n",
        "      graph: jraph.GraphsTuple,\n",
        "      is_training: bool,\n",
        "  ) -> jraph.GraphsTuple:\n",
        "    for idx in range(self._num_message_passing_steps):\n",
        "      net = build_gn(\n",
        "          output_sizes=self._output_sizes,\n",
        "          activation=self._activation,\n",
        "          suffix=str(idx),\n",
        "          use_sent_edges=self._use_sent_edges,\n",
        "          is_training=is_training,\n",
        "          dropedge_rate=self._dropedge_rate,\n",
        "          normalization_type=self._normalization_type,\n",
        "          aggregation_function=self._aggregation_function)\n",
        "      residual_graph = net(graph)\n",
        "      graph = graph._replace(nodes=graph.nodes + residual_graph.nodes)\n",
        "      if not self._disable_edge_updates:\n",
        "        graph = graph._replace(edges=graph.edges + residual_graph.edges)\n",
        "      if is_training:\n",
        "        graph = self._dropout_graph(graph)\n",
        "    return graph\n",
        "\n",
        "  def _node_mlp(\n",
        "      self,\n",
        "      graph: jraph.GraphsTuple,\n",
        "      is_training: bool,\n",
        "      output_size: int,\n",
        "      name: str,\n",
        "  ) -> jnp.ndarray:\n",
        "    decoder_sizes = list(self._output_sizes[:-1]) + [output_size]\n",
        "    net = build_update_fn(\n",
        "        name,\n",
        "        decoder_sizes,\n",
        "        self._activation,\n",
        "        normalization_type=self._normalization_type,\n",
        "        is_training=is_training,\n",
        "    )\n",
        "    return net(graph.nodes)\n",
        "\n",
        "  def __call__(\n",
        "      self,\n",
        "      graph: jraph.GraphsTuple,\n",
        "      is_training: bool,\n",
        "      stop_gradient_embedding_to_logits: bool = False,\n",
        "  ) -> ModelOutput:\n",
        "    # Note that these update configs may need to change if\n",
        "    # we switch back to GraphNetwork rather than InteractionNetwork.\n",
        "\n",
        "    graph = self._encode(graph, is_training)\n",
        "    graph = self._process(graph, is_training)\n",
        "    node_embeddings = graph.nodes\n",
        "    node_projections = self._node_mlp(graph, is_training, self._latent_size,\n",
        "                                      'projector')\n",
        "    node_predictions = self._node_mlp(\n",
        "        graph._replace(nodes=node_projections),\n",
        "        is_training,\n",
        "        self._latent_size,\n",
        "        'predictor',\n",
        "    )\n",
        "    if stop_gradient_embedding_to_logits:\n",
        "      graph = jax.tree_map(jax.lax.stop_gradient, graph)\n",
        "    node_logits = self._node_mlp(graph, is_training, self._num_classes,\n",
        "                                 'logits_decoder')\n",
        "    return ModelOutput(\n",
        "        node_embeddings=node_embeddings,\n",
        "        node_logits=node_logits,\n",
        "        node_embedding_projections=node_projections,\n",
        "        node_projection_predictions=node_predictions,\n",
        "    )"
      ],
      "metadata": {
        "id": "T4Hi36JhB5XU"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}