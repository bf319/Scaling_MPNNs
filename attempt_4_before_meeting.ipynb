{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attempt_4_before_meeting.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP77IWKDTGWB/KEY8P8H3h0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bf319/Scaling_MPNNs/blob/main/attempt_4_before_meeting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n3jpe18Q0gv3"
      },
      "outputs": [],
      "source": [
        "%pip install -q git+https://github.com/deepmind/dm-haiku\n",
        "%pip install -q jraph\n",
        "%pip install -q git+https://github.com/deepmind/jaxline\n",
        "%pip install -q ogb\n",
        "%pip install -q dgl\n",
        "%pip install -q optax\n",
        "%pip install -q metis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set up the TPU\n",
        "# import jax\n",
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()\n",
        "\n",
        "# device_count = jax.device_count() # 8 devices\n",
        "\n",
        "# jax.devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRwIV0rrejDb",
        "outputId": "47dca461-daa4-49ce-d5a5-5f3abcc07c73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from jax.experimental import maps\n",
        "# from jax.experimental import PartitionSpec\n",
        "# from jax.experimental.pjit import pjit\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# mesh_shape = (4, 2)\n",
        "# devices = np.asarray(jax.devices()).reshape(*mesh_shape)\n",
        "\n",
        "# mesh = maps.Mesh(devices, ('x', 'y'))\n",
        "# mesh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs8d3h1Phafp",
        "outputId": "c5ae9594-a015-4722-84be-c23a31c1db29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mesh(array([[0, 1],\n",
              "       [2, 3],\n",
              "       [4, 5],\n",
              "       [6, 7]]), ('x', 'y'))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.nodeproppred import Evaluator\n",
        "from ogb.nodeproppred import DglNodePropPredDataset\n",
        "\n",
        "\n",
        "dataset = DglNodePropPredDataset(name = \"ogbn-proteins\")\n",
        "split_idx = dataset.get_idx_split()\n",
        "evaluator = Evaluator(name = 'ogbn-proteins')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jIWxp1_0mIu",
        "outputId": "5573cb5e-8697-41b1-f3af-f97b43bb6eb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/proteins.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.21 GB: 100%|██████████| 216/216 [00:28<00:00,  7.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/proteins.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into DGL objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There is only one graph in Node Property Prediction datasets\n",
        "ogbn_proteins_main_graph, ogbn_proteins_main_labels = dataset[0]\n",
        "\n",
        "'''\n",
        "  OGBN-Proteins\n",
        "    #Nodes = 132,534\n",
        "    #Edges = 39,561,252\n",
        "    #Tasks = 112\n",
        "    #Split Type = Species\n",
        "    #Task Type = Binary classification\n",
        "    #Metric = ROC-AUC\n",
        "\n",
        "    Task:\n",
        "      The task is to predict the presence of protein functions in a multi-label binary classification setup,\n",
        "      where there are 112 kinds of labels to predict in total. \n",
        "      The performance is measured by the average of ROC-AUC scores across the 112 tasks.\n",
        "\n",
        "    #Others:\n",
        "      **undirected**\n",
        "      **weighted**\n",
        "      **typed (according to species)**\n",
        "\n",
        "  (1) Nodes represent proteins\n",
        "    (1.1) The proteins come from 8 species\n",
        "      len(set(graph.ndata['species'].reshape(-1).tolist())) == 8\n",
        "    (1.2) Each node has one feature associated with it (its species)\n",
        "      graph.ndata['species'].shape == (#nodes, 1)\n",
        "  \n",
        "  (2) Edges indicate different types of biologically meaningful associations between proteins\n",
        "    (2.1) All edges come with 8-dimensional features\n",
        "      graph.edata['feat'].shape == (2 * #edges, 8)\n",
        "\n",
        "'''\n",
        "# Get split labels\n",
        "train_label = dataset.labels[split_idx['train']]  # (86619, 112) -- binary values (presence of protein functions)\n",
        "valid_label = dataset.labels[split_idx['valid']]  # (21236, 112) -- binary values (presence of protein functions)\n",
        "test_label = dataset.labels[split_idx['test']]    # (24679, 112) -- binary values (presence of protein functions)"
      ],
      "metadata": {
        "id": "IHKbbygY0oTc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "\n",
        "'''\n",
        "  Generate graph partition using metis, with balanced number of edges in each partition.\n",
        "  Note: \n",
        "    The subgraphs do not contain the node/edge data in the input graph (https://docs.dgl.ai/generated/dgl.metis_partition.html)\n",
        "'''\n",
        "num_partitions = 100\n",
        "dgl_graph_metis_partition = dgl.metis_partition(ogbn_proteins_main_graph, num_partitions, balance_edges = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glmmxIPA0p1Y",
        "outputId": "1f6014de-b756-4111-e519-cdbd4a919329"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 1.977 seconds\n",
            "Construct multi-constraint weights: 0.021 seconds\n",
            "Metis partitioning: 33.155 seconds\n",
            "Split the graph: 0.579 seconds\n",
            "Construct subgraphs: 0.042 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import jraph\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def dgl_graph_to_jraph(node_ids):\n",
        "  # First add back the node and edge features\n",
        "  dgl_graph_with_features = dgl.node_subgraph(ogbn_proteins_main_graph, node_ids)\n",
        "\n",
        "  node_features = jnp.array(dgl_graph_with_features.ndata['species'])\n",
        "  \n",
        "  # I think it should be -- DGLGraph.edges uses the default (uv) format for edges\n",
        "  # with u == source and v == destination\n",
        "  # From https://docs.dgl.ai/generated/dgl.DGLGraph.edges.html#dgl.DGLGraph.edges\n",
        "  senders = jnp.array(dgl_graph_with_features.edges()[0])\n",
        "  receivers = jnp.array(dgl_graph_with_features.edges()[1])\n",
        "\n",
        "  # Edges -- here we should include the 8-dimensional edge features\n",
        "  edges = jnp.array(dgl_graph_with_features.edata['feat'])\n",
        "\n",
        "  n_node = jnp.array([dgl_graph_with_features.num_nodes()])\n",
        "  n_edge = jnp.array([dgl_graph_with_features.num_edges()])\n",
        "\n",
        "  return jraph.GraphsTuple(\n",
        "            nodes = node_features.astype(np.float32),\n",
        "            senders = senders.astype(np.int32), \n",
        "            receivers = receivers.astype(np.int32),\n",
        "            edges = edges.astype(np.float32),  \n",
        "            n_node = n_node, \n",
        "            n_edge = n_edge,\n",
        "            globals = None  # No global features\n",
        "          )\n",
        "  \n",
        "def get_labels_for_subgraph(node_ids):\n",
        "  return ogbn_proteins_main_labels.index_select(0, node_ids)"
      ],
      "metadata": {
        "id": "C9kl_E-b0vRw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import optax\n",
        "\n",
        "from typing import Sequence\n",
        "\n",
        "# See https://github.com/YuxuanXie/mcl/blob/5f7ee92e2a6bc89736263873a4ba9c14d1a676ff/glassy_dynamics/train_using_jax.py for alternative to using GraphMapFeatures\n",
        "# From https://github.com/YuxuanXie/mcl/blob/5f7ee92e2a6bc89736263873a4ba9c14d1a676ff/glassy_dynamics/train_using_jax.py\n",
        "\n",
        "mlp_sizes = (64, 128)\n",
        "num_message_passing_steps = 3\n",
        "\n",
        "@jraph.concatenated_args\n",
        "def node_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Node update function for graph net.\"\"\"\n",
        "  net = hk.Sequential([hk.nets.MLP(output_sizes = mlp_sizes), jax.nn.relu, hk.LayerNorm(axis = -1, create_scale = False, create_offset = False)])\n",
        "  return net(feats)\n",
        "\n",
        "@jraph.concatenated_args\n",
        "def edge_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Edge update function for graph net.\"\"\"\n",
        "  net = hk.Sequential([hk.nets.MLP(output_sizes = mlp_sizes), jax.nn.relu, hk.LayerNorm(axis = -1, create_scale = False, create_offset = False)])\n",
        "  return net(feats)\n",
        "\n",
        "def node_decoder_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
        "  ## TODO -- Question\n",
        "  ## Should I use softmax here then round the decoded values? (true labels are either 0 or 1) \n",
        "  net = hk.Sequential([hk.nets.MLP(output_sizes = [112]), jax.nn.relu])\n",
        "  return net(feats)\n",
        "\n",
        "def network_definition(graph):\n",
        "  \"\"\"Defines a graph neural network.\n",
        "  Args:\n",
        "    graph: Graphstuple the network processes.\n",
        "  Returns:\n",
        "    Decoded nodes.\n",
        "  \"\"\"\n",
        "\n",
        "  embedder = jraph.GraphMapFeatures(\n",
        "      embed_node_fn=hk.Linear(mlp_sizes[0]),\n",
        "      embed_edge_fn=hk.Linear(mlp_sizes[1]),\n",
        "      )\n",
        "  graph = embedder(graph)\n",
        "\n",
        "  gn = jraph.InteractionNetwork(\n",
        "      update_node_fn=node_update_fn,\n",
        "      update_edge_fn=edge_update_fn,\n",
        "      include_sent_messages_in_node_update=True\n",
        "      )\n",
        "\n",
        "  for _ in range(num_message_passing_steps):\n",
        "    graph = gn(graph)\n",
        "\n",
        "  decoder = jraph.GraphMapFeatures(embed_node_fn = node_decoder_fn)\n",
        "  \n",
        "  processed_graph = decoder(graph)\n",
        "  return processed_graph.nodes"
      ],
      "metadata": {
        "id": "u_QvbygF04bU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import haiku as hk\n",
        "\n",
        "from random import randint\n",
        "\n",
        "# Try to follow this tutorial https://github.com/YuxuanXie/mcl/blob/5f7ee92e2a6bc89736263873a4ba9c14d1a676ff/glassy_dynamics/train_using_jax.py\n",
        "def compute_loss(params, graph, label, net):\n",
        "  decoded_nodes = net.apply(params, graph) # Shape == label.shape\n",
        "  \n",
        "  ## TODO -- Question\n",
        "  ## Should I round the predictions here?\n",
        "  # predictions = jax.lax.round(decoded_nodes)\n",
        "  predictions = decoded_nodes\n",
        "\n",
        "  ##########################################################################################################################################################################\n",
        "  # From https://colab.research.google.com/github/deepmind/educational/blob/master/colabs/summer_schools/intro_to_graph_nets_tutorial_with_jraph.ipynb#scrollTo=_Ld4b3D6Lwel\n",
        "  ##########################################################################################################################################################################\n",
        "  def compute_bce_with_logits_loss(x: jnp.ndarray, y: jnp.ndarray) -> jnp.ndarray:\n",
        "    \"\"\"Computes binary cross-entropy with logits loss.\n",
        "\n",
        "    Combines sigmoid and BCE, and uses log-sum-exp trick for numerical stability.\n",
        "    See https://stackoverflow.com/a/66909858 if you want to learn more.\n",
        "\n",
        "    Args:\n",
        "      x: Predictions (logits).\n",
        "      y: Labels.\n",
        "\n",
        "    Returns:\n",
        "      Binary cross-entropy loss with mean aggregation.\n",
        "\n",
        "    \"\"\"\n",
        "    max_val = jnp.clip(x, 0, None)\n",
        "    loss = x - x * y + max_val + jnp.log(jnp.exp(-max_val) + jnp.exp((-x - max_val)))\n",
        "    return loss.mean()\n",
        "  ##########################################################################################################################################################################\n",
        "\n",
        "  loss = compute_bce_with_logits_loss(predictions, label)\n",
        "  return loss\n",
        "\n",
        "def train(num_training_steps):\n",
        "  # Transform the function (MPNN) into a pure function (with no side effects) so that it can be used with jax\n",
        "  net = hk.without_apply_rng(hk.transform(network_definition))\n",
        "\n",
        "  training_graph = dgl_graph_to_jraph(dgl_graph_metis_partition[0].ndata['_ID'])\n",
        "  labels_training = get_labels_for_subgraph(dgl_graph_metis_partition[0].ndata['_ID'])\n",
        "  labels_training = jnp.array(labels_training)\n",
        "\n",
        "  params = net.init(jax.random.PRNGKey(42), training_graph)\n",
        "\n",
        "  opt_init, opt_update = optax.adam(learning_rate = 1e-5)\n",
        "  opt_state = opt_init(params)\n",
        "\n",
        "  @jax.jit\n",
        "  def update(params, opt_state, graph, targets):\n",
        "    loss, grads = jax.value_and_grad(compute_loss)(params, graph, targets, net)\n",
        "    updates, opt_state = opt_update(grads, opt_state)\n",
        "    return optax.apply_updates(params, updates), opt_state, loss\n",
        "\n",
        "  ## TODO - Question\n",
        "  ## How to train only using the train_split?\n",
        "\n",
        "  # Train\n",
        "  for idx in range(num_training_steps):\n",
        "    ## TODO - Question\n",
        "    ## I should be training in each iteration over different graphs right?\n",
        "    graph_idx = dgl_graph_to_jraph(dgl_graph_metis_partition[idx].ndata['_ID'])\n",
        "    labels_idx = get_labels_for_subgraph(dgl_graph_metis_partition[idx].ndata['_ID'])\n",
        "    labels_idx = jnp.array(labels_idx)\n",
        "\n",
        "    params, opt_state, loss = update(params, opt_state, graph_idx, labels_idx)\n",
        "    print('Loss training:', loss)\n",
        "\n",
        "  return params\n",
        "\n",
        "def evaluate(params, num_graphs_eval):\n",
        "  net = hk.without_apply_rng(hk.transform(network_definition))\n",
        "  # Evaluate\n",
        "  accumulated_loss = 0.0\n",
        "  accumulated_roc = 0\n",
        "\n",
        "  for idx in range(num_graphs_eval):\n",
        "    graph_idx = dgl_graph_to_jraph(dgl_graph_metis_partition[idx].ndata['_ID'])\n",
        "    labels_idx = get_labels_for_subgraph(dgl_graph_metis_partition[idx].ndata['_ID'])\n",
        "    labels_idx = jnp.array(labels_idx)\n",
        "\n",
        "    (loss, roc) = evaluate_graph(params, graph_idx, labels_idx, net)\n",
        "\n",
        "    accumulated_loss += loss\n",
        "    accumulated_roc += roc\n",
        "\n",
        "  print(f'Average loss: {accumulated_loss / num_graphs_eval} | Average ROC: {accumulated_roc / num_graphs_eval}')\n",
        "\n",
        "def evaluate_graph(params, graph, label, net):\n",
        "  compute_loss_fn = jax.jit(functools.partial(compute_loss, net=net))\n",
        "\n",
        "  decoded_nodes = net.apply(params, graph) # Shape == label.shape\n",
        "  \n",
        "  ## TODO -- Question\n",
        "  ## Should I round the predictions here?\n",
        "  # predictions = jax.lax.round(decoded_nodes)\n",
        "  predictions = decoded_nodes\n",
        "\n",
        "  loss = compute_loss_fn(params, graph, label)\n",
        "  roc = evaluator.eval({\"y_true\": np.array(label), \"y_pred\": np.array(predictions)})['rocauc']\n",
        "\n",
        "  print(f'Eval loss: {loss} | ROC: {roc}')\n",
        "  return (loss, roc)\n",
        "\n",
        "final_params = train(num_training_steps = 10)\n",
        "evaluate(final_params, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2uzCUYg4gdw",
        "outputId": "b94848cb-0814-44c3-d519-634f149cddc4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss training: 0.87253135\n",
            "Loss training: 0.87605214\n",
            "Loss training: 0.8536194\n",
            "Loss training: 0.8679402\n",
            "Loss training: 0.86566395\n",
            "Loss training: 0.874914\n",
            "Loss training: 0.83846605\n",
            "Loss training: 0.85684824\n",
            "Loss training: 0.85161704\n",
            "Loss training: 0.8531333\n",
            "Eval loss: 0.8505326509475708 | ROC: 0.5033964674842418\n",
            "Eval loss: 0.8548594117164612 | ROC: 0.5002023731143936\n",
            "Eval loss: 0.8381888270378113 | ROC: 0.49774785969122265\n",
            "Eval loss: 0.8536170721054077 | ROC: 0.4943839687819653\n",
            "Eval loss: 0.8542311191558838 | ROC: 0.5056950122682095\n",
            "Average loss: 0.8502859473228455 | Average ROC: 0.5002851362680065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## TODO - Question\n",
        "## Problem with pjit on Google Colabs\n",
        "## https://github.com/google/jax/issues/8300\n",
        "\n",
        "# from jax.experimental import maps\n",
        "# from jax.experimental.pjit import PartitionSpec, pjit\n",
        "\n",
        "# def test_pjit():\n",
        "#   input_data = np.arange(8 * 2).reshape(8, 2)\n",
        "\n",
        "#   f = pjit(\n",
        "#     lambda x: x,\n",
        "#     in_axis_resources=None,\n",
        "#     out_axis_resources=PartitionSpec('x', 'y')\n",
        "#     )\n",
        " \n",
        "#   # Sends data to accelerators based on partition_spec\n",
        "#   with maps.mesh(mesh.devices, mesh.axis_names):\n",
        "#     data = f(input_data)\n",
        "\n",
        "#     print(data)\n",
        "#     print(data.device_buffers)\n",
        "\n",
        "# test_pjit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "SbW_joYk0wlV",
        "outputId": "6691030d-6ab0-40bf-c22b-ab9b848f0978"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/experimental/pjit.py:183: UserWarning: pjit is an experimental feature and probably has bugs!\n",
            "  warn(\"pjit is an experimental feature and probably has bugs!\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0a37fb2b1713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_buffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtest_pjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-0a37fb2b1713>\u001b[0m in \u001b[0;36mtest_pjit\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# Sends data to accelerators based on partition_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mmaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/experimental/pjit.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs_flat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0m_check_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpjit_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    277\u001b[0m     assert (not config.jax_enable_checks or\n\u001b[1;32m    278\u001b[0m             all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_top_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/experimental/pjit.py\u001b[0m in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_axis_resources, out_axis_resources, resource_env, donated_invars, name, in_positional_semantics, out_positional_semantics, *args)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_axis_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_axis_resources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0mresource_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdonated_invars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_positional_semantics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       out_positional_semantics).compile()\n\u001b[0m\u001b[1;32m    600\u001b[0m   distributed_debug_log((\"Running pjit'd function\", name),\n\u001b[1;32m    601\u001b[0m                         (\"mesh\", resource_env.physical_mesh))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, _allow_propagation_to_outputs, _allow_compile_replicated)\u001b[0m\n\u001b[1;32m   2265\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m           \u001b[0m_allow_propagation_to_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_allow_propagation_to_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2267\u001b[0;31m           _allow_compile_replicated=_allow_compile_replicated)  # type: ignore\n\u001b[0m\u001b[1;32m   2268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/pxla.py\u001b[0m in \u001b[0;36mfrom_hlo\u001b[0;34m(name, computation, mesh, global_in_avals, global_out_avals, in_axes, out_axes, spmd_lowering, tuple_args, in_is_gda, _allow_propagation_to_outputs, _allow_compile_replicated)\u001b[0m\n\u001b[1;32m   2351\u001b[0m       with dispatch.log_elapsed_time(f\"Finished XLA compilation of {name} \"\n\u001b[1;32m   2352\u001b[0m                                      \"in {elapsed_time} sec\"):\n\u001b[0;32m-> 2353\u001b[0;31m         \u001b[0mxla_executable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_or_get_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2354\u001b[0m       \u001b[0mhandle_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputsHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_executable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_specs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m       \u001b[0munsafe_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExecuteReplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_executable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, compile_options)\u001b[0m\n\u001b[1;32m    581\u001b[0m               else computation.as_hlo_text())\n\u001b[1;32m    582\u001b[0m     \u001b[0m_dump_ir_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options)\u001b[0m\n\u001b[1;32m    535\u001b[0m   \u001b[0;31m# we use a separate function call to ensure that XLA compilation appears\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m   \u001b[0;31m# separately in Python profiling results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilt_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;31m# TODO(phawkins): update users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: UNIMPLEMENTED: Only 1 computation per replica supported, 8 requested."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## TODO: Take into account that nodes might have been reshufled\n",
        "# def predict_labels(params, net):\n",
        "#   y_pred = None\n",
        "\n",
        "#   for i in range(num_partitions):\n",
        "#     graph = dgl_graph_to_jraph(dgl_graph_metis_partition[i].ndata['_ID'])\n",
        "\n",
        "#     if i == 0:\n",
        "#       y_pred = np.array(jax.nn.softmax(net.apply(params, graph)))\n",
        "#     else:\n",
        "#       if i % 5 == 0:\n",
        "#         print(f'Reached iteration {i}')\n",
        "#       y_pred = np.append(\n",
        "#           y_pred,\n",
        "#           np.array(jax.nn.softmax(net.apply(params, graph))),\n",
        "#           axis = 0\n",
        "#       )\n",
        "\n",
        "#   return y_pred"
      ],
      "metadata": {
        "id": "uQOOKRGyz9pH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (_, true_labels) = dataset[0]\n",
        "# print(true_labels.shape)\n",
        "# print(torch.tensor(predicted_labels).shape)"
      ],
      "metadata": {
        "id": "pXT6kbGjdMP2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from ogb.nodeproppred import Evaluator\n",
        "\n",
        "# evaluator = Evaluator(name = 'ogbn-proteins')\n",
        "# final_results = evaluator.eval({\n",
        "#     'y_true': true_labels,\n",
        "#     'y_pred': torch.tensor(predicted_labels)\n",
        "# })\n",
        "# print(final_results)\n",
        "# # print(evaluator.expected_input_format) \n",
        "# # print(evaluator.expected_output_format) "
      ],
      "metadata": {
        "id": "T5CMRumSzua-"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}