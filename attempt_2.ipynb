{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attempt-2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaDj3aNz/Cyp8IjxtvQXKi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bf319/Scaling_MPNNs/blob/main/attempt_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3jpe18Q0gv3",
        "outputId": "fe1f1665-06a5-40bd-dac4-8d965e186837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 75 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 70 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.0 MB/s \n",
            "\u001b[?25h  Building wheel for jaxline (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.2 MB/s \n",
            "\u001b[?25h  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 4.1 MB/s \n",
            "\u001b[?25h  Building wheel for metis (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q git+https://github.com/deepmind/dm-haiku\n",
        "%pip install -q jraph\n",
        "%pip install -q git+https://github.com/deepmind/jaxline\n",
        "%pip install -q ogb\n",
        "%pip install -q dgl\n",
        "%pip install -q optax\n",
        "%pip install -q metis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.nodeproppred import Evaluator\n",
        "from ogb.nodeproppred import DglNodePropPredDataset\n",
        "\n",
        "dataset = DglNodePropPredDataset(name = \"ogbn-proteins\")\n",
        "split_idx = dataset.get_idx_split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jIWxp1_0mIu",
        "outputId": "390165ea-f555-4ad2-8f48-3b0f11a87b31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/proteins.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.21 GB: 100%|██████████| 216/216 [00:16<00:00, 12.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/proteins.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into DGL objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There is only one graph in Node Property Prediction datasets\n",
        "ogbn_proteins_main_graph, ogbn_proteins_main_labels = dataset[0]\n",
        "\n",
        "'''\n",
        "  OGBN-Proteins\n",
        "    #Nodes = 132,534\n",
        "    #Edges = 39,561,252\n",
        "    #Tasks = 112\n",
        "    #Split Type = Species\n",
        "    #Task Type = Binary classification\n",
        "    #Metric = ROC-AUC\n",
        "\n",
        "    Task:\n",
        "      The task is to predict the presence of protein functions in a multi-label binary classification setup,\n",
        "      where there are 112 kinds of labels to predict in total. \n",
        "      The performance is measured by the average of ROC-AUC scores across the 112 tasks.\n",
        "\n",
        "    #Others:\n",
        "      **undirected**\n",
        "      **weighted**\n",
        "      **typed (according to species)**\n",
        "\n",
        "  (1) Nodes represent proteins\n",
        "    (1.1) The proteins come from 8 species\n",
        "      len(set(graph.ndata['species'].reshape(-1).tolist())) == 8\n",
        "    (1.2) Each node has one feature associated with it (its species)\n",
        "      graph.ndata['species'].shape == (#nodes, 1)\n",
        "  \n",
        "  (2) Edges indicate different types of biologically meaningful associations between proteins\n",
        "    (2.1) All edges come with 8-dimensional features\n",
        "      graph.edata['feat'].shape == (2 * #edges, 8)\n",
        "\n",
        "'''\n",
        "# Get split labels\n",
        "train_label = dataset.labels[split_idx['train']]  # (86619, 112) -- binary values (presence of protein functions)\n",
        "valid_label = dataset.labels[split_idx['valid']]  # (21236, 112) -- binary values (presence of protein functions)\n",
        "test_label = dataset.labels[split_idx['test']]    # (24679, 112) -- binary values (presence of protein functions)"
      ],
      "metadata": {
        "id": "IHKbbygY0oTc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "\n",
        "'''\n",
        "  Generate graph partition using metis, with balanced number of edges in each partition.\n",
        "  Note: \n",
        "    The subgraphs do not contain the node/edge data in the input graph (https://docs.dgl.ai/generated/dgl.metis_partition.html)\n",
        "'''\n",
        "num_partitions = 100\n",
        "dgl_graph_metis_partition = dgl.metis_partition(ogbn_proteins_main_graph, num_partitions, balance_edges = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glmmxIPA0p1Y",
        "outputId": "e2bf1771-38f9-45df-a86a-7e010e15f2be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 5.454 seconds\n",
            "Construct multi-constraint weights: 0.108 seconds\n",
            "Metis partitioning: 41.460 seconds\n",
            "Split the graph: 5.518 seconds\n",
            "Construct subgraphs: 0.126 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import jraph\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def dgl_graph_to_jraph(node_ids):\n",
        "  # First add back the node and edge features\n",
        "  dgl_graph_with_features = dgl.node_subgraph(ogbn_proteins_main_graph, node_ids)\n",
        "\n",
        "  node_features = jnp.array(dgl_graph_with_features.ndata['species'])\n",
        "  \n",
        "  # TODO: Check if order is correct\n",
        "  # I think it should be -- DGLGraph.edges uses the default (uv) format for edges\n",
        "  # with u == source and v == destination\n",
        "  # From https://docs.dgl.ai/generated/dgl.DGLGraph.edges.html#dgl.DGLGraph.edges\n",
        "  senders = jnp.array(dgl_graph_with_features.edges()[0])\n",
        "  receivers = jnp.array(dgl_graph_with_features.edges()[1])\n",
        "\n",
        "  # Edges -- here we should include the 8-dimensional edge features\n",
        "  edges = jnp.array(dgl_graph_with_features.edata['feat'])\n",
        "\n",
        "  n_node = jnp.array([dgl_graph_with_features.num_nodes()])\n",
        "  n_edge = jnp.array([dgl_graph_with_features.num_edges()])\n",
        "\n",
        "  return jraph.GraphsTuple(\n",
        "            nodes = node_features.astype(np.float32),\n",
        "            senders = senders.astype(np.int32), \n",
        "            receivers = receivers.astype(np.int32),\n",
        "            edges = edges.astype(np.float32),  \n",
        "            n_node = n_node, \n",
        "            n_edge = n_edge,\n",
        "            globals = None  # No global features\n",
        "          )\n",
        "  \n",
        "def get_labels_for_subgraph(node_ids):\n",
        "  return ogbn_proteins_main_labels.index_select(0, node_ids)"
      ],
      "metadata": {
        "id": "C9kl_E-b0vRw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jraph\n",
        "import optax"
      ],
      "metadata": {
        "id": "y_xmEvt50yZQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q flax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSXj1i_A1W-C",
        "outputId": "6a0525d8-e96d-4869-d3a0-fa1aaf758884"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 4.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence\n",
        "\n",
        "# From https://github.com/YuxuanXie/mcl/blob/5f7ee92e2a6bc89736263873a4ba9c14d1a676ff/glassy_dynamics/train_using_jax.py\n",
        "\n",
        "def network_definition(graph):\n",
        "  \"\"\"Defines a graph neural network.\n",
        "  Args:\n",
        "    graph: Graphstuple the network processes.\n",
        "  Returns:\n",
        "    Decoded nodes.\n",
        "  \"\"\"\n",
        "  model_fn = functools.partial(\n",
        "      hk.nets.MLP,\n",
        "      w_init=hk.initializers.VarianceScaling(1.0),\n",
        "      b_init=hk.initializers.VarianceScaling(1.0))\n",
        "  mlp_sizes = (64, 64)\n",
        "  num_message_passing_steps = 7\n",
        "\n",
        "  node_encoder = model_fn(output_sizes=mlp_sizes, activate_final=True)\n",
        "  edge_encoder = model_fn(output_sizes=mlp_sizes, activate_final=True)\n",
        "  node_decoder = model_fn(output_sizes=[112], activate_final=False)\n",
        "\n",
        "  node_encoding = node_encoder(graph.nodes)\n",
        "  edge_encoding = edge_encoder(graph.edges)\n",
        "  graph = graph._replace(nodes=node_encoding, edges=edge_encoding)\n",
        "\n",
        "  update_edge_fn = jraph.concatenated_args(\n",
        "      model_fn(output_sizes=mlp_sizes, activate_final=True))\n",
        "  update_node_fn = jraph.concatenated_args(\n",
        "      model_fn(output_sizes=mlp_sizes, activate_final=True))\n",
        "\n",
        "  gn = jraph.InteractionNetwork(\n",
        "      update_edge_fn=update_edge_fn,\n",
        "      update_node_fn=update_node_fn,\n",
        "      include_sent_messages_in_node_update=True)\n",
        "\n",
        "  for _ in range(num_message_passing_steps):\n",
        "    graph = graph._replace(\n",
        "        nodes=jnp.concatenate([graph.nodes, node_encoding], axis=-1),\n",
        "        edges=jnp.concatenate([graph.edges, edge_encoding], axis=-1))\n",
        "    graph = gn(graph)\n",
        "\n",
        "  # return jnp.squeeze(node_decoder(graph.nodes), axis=-1)\n",
        "  return node_decoder(graph.nodes)\n"
      ],
      "metadata": {
        "id": "u_QvbygF04bU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import haiku as hk\n",
        "\n",
        "# Try to follow this tutorial https://github.com/YuxuanXie/mcl/blob/5f7ee92e2a6bc89736263873a4ba9c14d1a676ff/glassy_dynamics/train_using_jax.py\n",
        "\n",
        "def compute_loss(params, graph, label, net):\n",
        "  decoded_nodes = net.apply(params, graph) # Shape == label.shape\n",
        "  predictions = jax.nn.softmax(decoded_nodes)\n",
        "\n",
        "  # loss = -jnp.mean(predictions * label)\n",
        "  loss = jnp.sum((predictions - label)**2)\n",
        "  # loss = -jnp.sum(label * jnp.log(predictions) + (1 - label) * jnp.log(1 - predictions))\n",
        "\n",
        "  return loss\n",
        "\n",
        "# def train_step(optimizer, graph, label, net):\n",
        "#   partial_loss_fn = functools.partial(\n",
        "#       compute_loss, graph=graph, label=label, net=net)\n",
        "#   grad_fn = jax.value_and_grad(partial_loss_fn, has_aux=True)\n",
        "#   loss, grad = grad_fn(optimizer.target)\n",
        "#   optimizer = optimizer.apply_gradient(grad)\n",
        "#   return optimizer, loss\n",
        "\n",
        "def evaluate(params, graph, label, net):\n",
        "  accumulated_loss = 0\n",
        "  accumulated_accuracy = 0\n",
        "  idx = 0\n",
        "\n",
        "  # net = GraphNetwork(mlp_features=[112], latent_size=128)\n",
        "  compute_loss_fn = jax.jit(functools.partial(compute_loss, net=net))\n",
        "\n",
        "  ## Evaluate on a batch of graphs\n",
        "  for i in range(10, 11):\n",
        "    loss = compute_loss_fn(params, graph, label)\n",
        "    acc = jnp.sum(jax.nn.softmax(net.apply(params, graph)) == label) / (label.shape[0] * label.shape[1])\n",
        "    idx += 1\n",
        "\n",
        "    print('Softmax')\n",
        "    # print(np.unique(np.array(jax.nn.softmax(net.apply(params, graph))), return_counts = True))\n",
        "    print(np.array(jax.nn.softmax(net.apply(params, graph)))[5])\n",
        "    print()\n",
        "    print()\n",
        "    print('Labels')\n",
        "    print(label)\n",
        "\n",
        "    ## After evaluating on a number of graphs, compute the mean loss and accuracy\n",
        "    accumulated_loss += loss\n",
        "    accumulated_accuracy += acc\n",
        "\n",
        "  print(f'Eval loss: {accumulated_loss / idx} | Accuracy: {accumulated_accuracy / idx}')\n",
        "\n",
        "def train_and_evaluate(num_training_steps):\n",
        "  # net = GraphNetwork(mlp_features = [112], latent_size = 128)\n",
        "  net = hk.without_apply_rng(hk.transform(network_definition))\n",
        "\n",
        "  training_graph = dgl_graph_to_jraph(dgl_graph_metis_partition[0].ndata['_ID'])\n",
        "  labels_training = get_labels_for_subgraph(dgl_graph_metis_partition[0].ndata['_ID'])\n",
        "  labels_training = jnp.array(labels_training)\n",
        "\n",
        "  params = net.init(jax.random.PRNGKey(42), training_graph)\n",
        "\n",
        "  opt_init, opt_update = optax.adam(learning_rate = 1e-5)\n",
        "  opt_state = opt_init(params)\n",
        "\n",
        "  @jax.jit\n",
        "  def update(params, opt_state, graph, targets):\n",
        "    loss, grads = jax.value_and_grad(compute_loss)(params, graph, targets, net)\n",
        "    updates, opt_state = opt_update(grads, opt_state)\n",
        "    return optax.apply_updates(params, updates), opt_state, loss\n",
        "\n",
        "  # Train\n",
        "  for idx in range(1, num_training_steps):\n",
        "    # optimizer, scalars = train_step(optimizer, training_graph, labels_training, net)\n",
        "    graph = dgl_graph_to_jraph(dgl_graph_metis_partition[idx].ndata['_ID'])\n",
        "    label = get_labels_for_subgraph(dgl_graph_metis_partition[idx].ndata['_ID'])\n",
        "    label = jnp.array(label)\n",
        "\n",
        "    params, opt_state, loss = update(params, opt_state, graph, label)\n",
        "    print('Loss training:', loss)\n",
        "\n",
        "  # Evaluate\n",
        "  evaluate(params, training_graph, labels_training, net)\n",
        "\n",
        "  predicted_labels = predict_labels(params, net)\n",
        "\n",
        "  return predicted_labels\n",
        "\n",
        "predicted_labels = train_and_evaluate(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2uzCUYg4gdw",
        "outputId": "79464d2a-13a8-49e6-8ba4-c7f7e7ea3591"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "\n",
            "Labels\n",
            "[[1 1 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Eval loss: 17787.0 | Accuracy: 0.8732399344444275\n",
            "Reached iteration 5\n",
            "Reached iteration 10\n",
            "Reached iteration 15\n",
            "Reached iteration 20\n",
            "Reached iteration 25\n",
            "Reached iteration 30\n",
            "Reached iteration 35\n",
            "Reached iteration 40\n",
            "Reached iteration 45\n",
            "Reached iteration 50\n",
            "Reached iteration 55\n",
            "Reached iteration 60\n",
            "Reached iteration 65\n",
            "Reached iteration 70\n",
            "Reached iteration 75\n",
            "Reached iteration 80\n",
            "Reached iteration 85\n",
            "Reached iteration 90\n",
            "Reached iteration 95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_labels(params, net):\n",
        "  y_pred = None\n",
        "\n",
        "  for i in range(num_partitions):\n",
        "    graph = dgl_graph_to_jraph(dgl_graph_metis_partition[i].ndata['_ID'])\n",
        "\n",
        "    if i == 0:\n",
        "      y_pred = np.array(jax.nn.softmax(net.apply(params, graph)))\n",
        "    else:\n",
        "      if i % 5 == 0:\n",
        "        print(f'Reached iteration {i}')\n",
        "      y_pred = np.append(\n",
        "          y_pred,\n",
        "          np.array(jax.nn.softmax(net.apply(params, graph))),\n",
        "          axis = 0\n",
        "      )\n",
        "\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "uQOOKRGyz9pH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(_, true_labels) = dataset[0]\n",
        "print(true_labels.shape)\n",
        "print(torch.tensor(predicted_labels).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXT6kbGjdMP2",
        "outputId": "264c8d89-5f6d-41a9-9d28-f24262a07835"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([132534, 112])\n",
            "torch.Size([132534, 112])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.nodeproppred import Evaluator\n",
        "\n",
        "evaluator = Evaluator(name = 'ogbn-proteins')\n",
        "final_results = evaluator.eval({\n",
        "    'y_true': true_labels,\n",
        "    'y_pred': torch.tensor(predicted_labels)\n",
        "})\n",
        "print(final_results)\n",
        "# print(evaluator.expected_input_format) \n",
        "# print(evaluator.expected_output_format) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5CMRumSzua-",
        "outputId": "c335bfe1-4257-4b28-fa2e-aed6cf5397a7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rocauc': 0.5000289552030827}\n"
          ]
        }
      ]
    }
  ]
}