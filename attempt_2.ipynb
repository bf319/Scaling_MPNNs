{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attempt-2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9eAorv2ktXCDkhZ7Yr3be",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bf319/Scaling_MPNNs/blob/main/attempt_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n3jpe18Q0gv3"
      },
      "outputs": [],
      "source": [
        "%pip install -q git+https://github.com/deepmind/dm-haiku\n",
        "%pip install -q jraph\n",
        "%pip install -q git+https://github.com/deepmind/jaxline\n",
        "%pip install -q ogb\n",
        "%pip install -q dgl\n",
        "%pip install -q optax\n",
        "%pip install -q metis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.nodeproppred import Evaluator\n",
        "from ogb.nodeproppred import DglNodePropPredDataset\n",
        "\n",
        "dataset = DglNodePropPredDataset(name = \"ogbn-proteins\")\n",
        "split_idx = dataset.get_idx_split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jIWxp1_0mIu",
        "outputId": "c6c96f83-6fac-4a1f-ac2b-3f023a815425"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There is only one graph in Node Property Prediction datasets\n",
        "ogbn_proteins_main_graph, ogbn_proteins_main_labels = dataset[0]\n",
        "\n",
        "'''\n",
        "  OGBN-Proteins\n",
        "    #Nodes = 132,534\n",
        "    #Edges = 39,561,252\n",
        "    #Tasks = 112\n",
        "    #Split Type = Species\n",
        "    #Task Type = Binary classification\n",
        "    #Metric = ROC-AUC\n",
        "\n",
        "    Task:\n",
        "      The task is to predict the presence of protein functions in a multi-label binary classification setup,\n",
        "      where there are 112 kinds of labels to predict in total. \n",
        "      The performance is measured by the average of ROC-AUC scores across the 112 tasks.\n",
        "\n",
        "    #Others:\n",
        "      **undirected**\n",
        "      **weighted**\n",
        "      **typed (according to species)**\n",
        "\n",
        "  (1) Nodes represent proteins\n",
        "    (1.1) The proteins come from 8 species\n",
        "      len(set(graph.ndata['species'].reshape(-1).tolist())) == 8\n",
        "    (1.2) Each node has one feature associated with it (its species)\n",
        "      graph.ndata['species'].shape == (#nodes, 1)\n",
        "  \n",
        "  (2) Edges indicate different types of biologically meaningful associations between proteins\n",
        "    (2.1) All edges come with 8-dimensional features\n",
        "      graph.edata['feat'].shape == (2 * #edges, 8)\n",
        "\n",
        "'''\n",
        "# Get split labels\n",
        "train_label = dataset.labels[split_idx['train']]  # (86619, 112) -- binary values (presence of protein functions)\n",
        "valid_label = dataset.labels[split_idx['valid']]  # (21236, 112) -- binary values (presence of protein functions)\n",
        "test_label = dataset.labels[split_idx['test']]    # (24679, 112) -- binary values (presence of protein functions)"
      ],
      "metadata": {
        "id": "IHKbbygY0oTc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "\n",
        "'''\n",
        "  Generate graph partition using metis, with balanced number of edges in each partition.\n",
        "  Note: \n",
        "    The subgraphs do not contain the node/edge data in the input graph (https://docs.dgl.ai/generated/dgl.metis_partition.html)\n",
        "'''\n",
        "num_partitions = 100\n",
        "dgl_graph_metis_partition = dgl.metis_partition(ogbn_proteins_main_graph, num_partitions, balance_edges = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glmmxIPA0p1Y",
        "outputId": "0780dbd0-28a0-4844-9f13-b2364c058f83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 6.486 seconds\n",
            "Construct multi-constraint weights: 0.005 seconds\n",
            "Metis partitioning: 44.488 seconds\n",
            "Split the graph: 5.638 seconds\n",
            "Construct subgraphs: 0.055 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import jraph\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def dgl_graph_to_jraph(node_ids):\n",
        "  # First add back the node and edge features\n",
        "  dgl_graph_with_features = dgl.node_subgraph(ogbn_proteins_main_graph, node_ids)\n",
        "\n",
        "  node_features = jnp.array(dgl_graph_with_features.ndata['species'])\n",
        "  \n",
        "  # TODO: Check if order is correct\n",
        "  # I think it should be -- DGLGraph.edges uses the default (uv) format for edges\n",
        "  # with u == source and v == destination\n",
        "  # From https://docs.dgl.ai/generated/dgl.DGLGraph.edges.html#dgl.DGLGraph.edges\n",
        "  senders = jnp.array(dgl_graph_with_features.edges()[0])\n",
        "  receivers = jnp.array(dgl_graph_with_features.edges()[1])\n",
        "\n",
        "  # Edges -- here we should include the 8-dimensional edge features\n",
        "  edges = jnp.array(dgl_graph_with_features.edata['feat'])\n",
        "\n",
        "  n_node = jnp.array([dgl_graph_with_features.num_nodes()])\n",
        "  n_edge = jnp.array([dgl_graph_with_features.num_edges()])\n",
        "\n",
        "  return jraph.GraphsTuple(\n",
        "            nodes = node_features.astype(np.float32),\n",
        "            senders = senders.astype(np.int32), \n",
        "            receivers = receivers.astype(np.int32),\n",
        "            edges = edges.astype(np.float32),  \n",
        "            n_node = n_node, \n",
        "            n_edge = n_edge,\n",
        "            globals = None  # No global features\n",
        "          )\n",
        "  \n",
        "def get_labels_for_subgraph(node_ids):\n",
        "  return ogbn_proteins_main_labels.index_select(0, node_ids)"
      ],
      "metadata": {
        "id": "C9kl_E-b0vRw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jraph\n",
        "import optax"
      ],
      "metadata": {
        "id": "y_xmEvt50yZQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q flax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSXj1i_A1W-C",
        "outputId": "85a35b68-a6c3-40c9-82a2-1458da5312b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 102 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 133 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 163 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 174 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 14.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence\n",
        "\n",
        "def network_definition(graph):\n",
        "  \"\"\"Defines a graph neural network.\n",
        "  Args:\n",
        "    graph: Graphstuple the network processes.\n",
        "  Returns:\n",
        "    Decoded nodes.\n",
        "  \"\"\"\n",
        "  model_fn = functools.partial(\n",
        "      hk.nets.MLP,\n",
        "      w_init=hk.initializers.VarianceScaling(1.0),\n",
        "      b_init=hk.initializers.VarianceScaling(1.0))\n",
        "  mlp_sizes = (64, 64)\n",
        "  num_message_passing_steps = 7\n",
        "\n",
        "  node_encoder = model_fn(output_sizes=mlp_sizes, activate_final=True)\n",
        "  edge_encoder = model_fn(output_sizes=mlp_sizes, activate_final=True)\n",
        "  node_decoder = model_fn(output_sizes=[112], activate_final=False)\n",
        "\n",
        "  node_encoding = node_encoder(graph.nodes)\n",
        "  edge_encoding = edge_encoder(graph.edges)\n",
        "  graph = graph._replace(nodes=node_encoding, edges=edge_encoding)\n",
        "\n",
        "  update_edge_fn = jraph.concatenated_args(\n",
        "      model_fn(output_sizes=mlp_sizes, activate_final=True))\n",
        "  update_node_fn = jraph.concatenated_args(\n",
        "      model_fn(output_sizes=mlp_sizes, activate_final=True))\n",
        "  gn = jraph.InteractionNetwork(\n",
        "      update_edge_fn=update_edge_fn,\n",
        "      update_node_fn=update_node_fn,\n",
        "      include_sent_messages_in_node_update=True)\n",
        "  \n",
        "  for _ in range(num_message_passing_steps):\n",
        "    graph = graph._replace(\n",
        "        nodes=jnp.concatenate([graph.nodes, node_encoding], axis=-1),\n",
        "        edges=jnp.concatenate([graph.edges, edge_encoding], axis=-1))\n",
        "    graph = gn(graph)\n",
        "\n",
        "  # return jnp.squeeze(node_decoder(graph.nodes), axis=-1)\n",
        "  return node_decoder(graph.nodes)\n"
      ],
      "metadata": {
        "id": "u_QvbygF04bU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import haiku as hk\n",
        "\n",
        "# Try to follow this tutorial https://github.com/YuxuanXie/mcl/blob/5f7ee92e2a6bc89736263873a4ba9c14d1a676ff/glassy_dynamics/train_using_jax.py\n",
        "\n",
        "def compute_loss(params, graph, label, net):\n",
        "  decoded_nodes = net.apply(params, graph) # Shape == label.shape\n",
        "  predictions = jax.nn.softmax(decoded_nodes)\n",
        "\n",
        "  loss = -jnp.mean(predictions * label)\n",
        "\n",
        "  return loss\n",
        "\n",
        "# def train_step(optimizer, graph, label, net):\n",
        "#   partial_loss_fn = functools.partial(\n",
        "#       compute_loss, graph=graph, label=label, net=net)\n",
        "#   grad_fn = jax.value_and_grad(partial_loss_fn, has_aux=True)\n",
        "#   loss, grad = grad_fn(optimizer.target)\n",
        "#   optimizer = optimizer.apply_gradient(grad)\n",
        "#   return optimizer, loss\n",
        "\n",
        "def evaluate(params, graph, label):\n",
        "  accumulated_loss = 0\n",
        "  accumulated_accuracy = 0\n",
        "  idx = 0\n",
        "\n",
        "  # net = GraphNetwork(mlp_features=[112], latent_size=128)\n",
        "  net = hk.without_apply_rng(hk.transform(network_definition))\n",
        "  compute_loss_fn = jax.jit(functools.partial(compute_loss, net=net))\n",
        "\n",
        "  ## Evaluate on a batch of graphs\n",
        "  loss = compute_loss_fn(params, graph, label)\n",
        "  acc = jnp.sum(jax.nn.softmax(net.apply(params, graph)) == label) / (label.shape[0] * label.shape[1])\n",
        "  idx += 1\n",
        "\n",
        "  ## After evaluating on a number of graphs, compute the mean loss and accuracy\n",
        "  accumulated_loss += loss\n",
        "  accumulated_accuracy += acc\n",
        "\n",
        "  print(f'Eval loss: {accumulated_loss / idx} | Accuracy: {accumulated_accuracy / idx}')\n",
        "\n",
        "def train_and_evaluate(num_training_steps):\n",
        "  # net = GraphNetwork(mlp_features = [112], latent_size = 128)\n",
        "  net = hk.without_apply_rng(hk.transform(network_definition))\n",
        "\n",
        "  training_graph = dgl_graph_to_jraph(dgl_graph_metis_partition[0].ndata['_ID'])\n",
        "  labels_training = get_labels_for_subgraph(dgl_graph_metis_partition[0].ndata['_ID'])\n",
        "  labels_training = jnp.array(labels_training)\n",
        "\n",
        "  params = net.init(jax.random.PRNGKey(42), training_graph)\n",
        "\n",
        "  opt_init, opt_update = optax.adam(learning_rate = 1e-5)\n",
        "  opt_state = opt_init(params)\n",
        "\n",
        "  @jax.jit\n",
        "  def update(params, opt_state, graph, targets):\n",
        "    loss, grads = jax.value_and_grad(compute_loss)(params, graph, targets, net)\n",
        "    updates, opt_state = opt_update(grads, opt_state)\n",
        "    return optax.apply_updates(params, updates), opt_state, loss\n",
        "\n",
        "  # Train\n",
        "  for idx in range(num_training_steps):\n",
        "    # optimizer, scalars = train_step(optimizer, training_graph, labels_training, net)\n",
        "    graph = dgl_graph_to_jraph(dgl_graph_metis_partition[idx].ndata['_ID'])\n",
        "    label = get_labels_for_subgraph(dgl_graph_metis_partition[idx].ndata['_ID'])\n",
        "    label = jnp.array(label)\n",
        "\n",
        "    params, opt_state, loss = update(params, opt_state, graph, label)\n",
        "    print('Loss training:', loss)\n",
        "\n",
        "  # Evaluate\n",
        "  evaluate(params, training_graph, labels_training)\n",
        "\n",
        "train_and_evaluate(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2uzCUYg4gdw",
        "outputId": "69b5b730-aec5-4dc7-b7a7-557652a82131"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss training: -0.0022140632\n",
            "Loss training: -0.0010719331\n",
            "Loss training: -0.00086903904\n",
            "Loss training: -0.0016110134\n",
            "Loss training: -0.0018560488\n",
            "Eval loss: -0.0022140631917864084 | Accuracy: 0.8766355514526367\n"
          ]
        }
      ]
    }
  ]
}